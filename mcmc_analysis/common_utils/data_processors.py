"""
–ü—Ä–æ—Ü–µ—Å–æ—Ä–∏ –∑–∞ —Å—É—Ä–æ–≤–∏ –¥–∞–Ω–Ω–∏
========================

–¢–æ–∑–∏ –º–æ–¥—É–ª –æ–±—Ä–∞–±–æ—Ç–≤–∞ —Å—É—Ä–æ–≤–∏ –¥–∞–Ω–Ω–∏ –æ—Ç:
- SH0ES (Supernovae H0 for the Equation of State)
- Pantheon+ (Supernovae Catalog)
- –î—Ä—É–≥–∏ –∫–æ—Å–º–æ–ª–æ–≥–∏—á–Ω–∏ –∏–∑–º–µ—Ä–≤–∞–Ω–∏—è

–ë–ï–ó ŒõCDM –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ - —Å–∞–º–æ —Å—É—Ä–æ–≤–∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è!

–ê–≤—Ç–æ—Ä: –°–∏—Å—Ç–µ–º–∞ –∑–∞ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –Ω–µ–ª–∏–Ω–µ–π–Ω–æ –≤—Ä–µ–º–µ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from astropy.io import fits
from astropy.table import Table
import re
import warnings
from typing import Dict, List, Tuple, Any, Optional
import os

warnings.filterwarnings('ignore')


class RawDataProcessor:
    """
    –û—Å–Ω–æ–≤–µ–Ω –∫–ª–∞—Å –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ —Å—É—Ä–æ–≤–∏ –¥–∞–Ω–Ω–∏
    """
    
    def __init__(self, data_path: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –ø—Ä–æ—Ü–µ—Å–æ—Ä–∞
        
        Args:
            data_path: –ü—ä—Ç –∫—ä–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ç–∞ —Å –¥–∞–Ω–Ω–∏
        """
        self.data_path = data_path or r"D:\MyPRJ\Python\NotLinearTime\test_2\data"
        self.loaded_data = {}
        
    def load_pantheon_plus_data(self) -> Dict[str, Any]:
        """
        –ó–∞—Ä–µ–∂–¥–∞ —Å—É—Ä–æ–≤–∏ –¥–∞–Ω–Ω–∏ –æ—Ç Pantheon+
        
        Returns:
            –†–µ—á–Ω–∏–∫ —Å –¥–∞–Ω–Ω–∏
        """
        pantheon_path = os.path.join(self.data_path, "Pantheon+_Data")
        
        data = {}
        
        # 1. –ó–∞—Ä–µ–∂–¥–∞–º–µ –æ—Å–Ω–æ–≤–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏ –æ—Ç —Ä–∞–∑–ª–∏—á–Ω–∏—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for subdir in ['1_DATA', '2_CALIBRATION', '3_SALT2', '4_DISTANCES_AND_COVAR']:
            subdir_path = os.path.join(pantheon_path, subdir)
            if os.path.exists(subdir_path):
                data[subdir] = self._load_directory_files(subdir_path)
        
        # 2. –û—Å–Ω–æ–≤–Ω–∏—è—Ç –∫–∞—Ç–∞–ª–æ–≥ —Å —Ä–µ–∑—É–ª—Ç–∞—Ç–∏
        main_files = self._load_directory_files(pantheon_path)
        data['main'] = main_files
        
        self.loaded_data['pantheon_plus'] = data
        return data
    
    def load_shoes_data(self) -> Dict[str, Any]:
        """
        –ó–∞—Ä–µ–∂–¥–∞ —Å—É—Ä–æ–≤–∏ –¥–∞–Ω–Ω–∏ –æ—Ç SH0ES
        
        Returns:
            –†–µ—á–Ω–∏–∫ —Å –¥–∞–Ω–Ω–∏
        """
        shoes_path = os.path.join(self.data_path, "SH0ES_Data")
        
        data = {}
        
        # –ó–∞—Ä–µ–∂–¥–∞–º–µ –≤—Å–∏—á–∫–∏ —Ñ–∞–π–ª–æ–≤–µ
        for filename in os.listdir(shoes_path):
            file_path = os.path.join(shoes_path, filename)
            
            if filename.endswith('.fits'):
                # FITS —Ñ–∞–π–ª–æ–≤–µ
                data[filename] = self._load_fits_file(file_path)
            elif filename.endswith('.dat'):
                # ASCII –¥–∞–Ω–Ω–∏
                data[filename] = self._load_ascii_file(file_path)
            elif filename.endswith('.tex'):
                # LaTeX —Ç–∞–±–ª–∏—Ü–∏
                data[filename] = self._load_latex_table(file_path)
            elif filename.endswith('.out'):
                # –ò–∑—Ö–æ–¥–Ω–∏ —Ñ–∞–π–ª–æ–≤–µ
                data[filename] = self._load_ascii_file(file_path)
        
        self.loaded_data['shoes'] = data
        return data
    
    def _load_directory_files(self, directory: str) -> Dict[str, Any]:
        """
        –ó–∞—Ä–µ–∂–¥–∞ –≤—Å–∏—á–∫–∏ —Ñ–∞–π–ª–æ–≤–µ –æ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        
        Args:
            directory: –ü—ä—Ç –∫—ä–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ç–∞
            
        Returns:
            –†–µ—á–Ω–∏–∫ —Å –¥–∞–Ω–Ω–∏
        """
        data = {}
        
        if not os.path.exists(directory):
            return data
        
        for filename in os.listdir(directory):
            file_path = os.path.join(directory, filename)
            
            if os.path.isfile(file_path):
                try:
                    if filename.endswith('.fits'):
                        data[filename] = self._load_fits_file(file_path)
                    elif filename.endswith(('.dat', '.txt', '.csv')):
                        data[filename] = self._load_ascii_file(file_path)
                    elif filename.endswith('.tex'):
                        data[filename] = self._load_latex_table(file_path)
                except Exception as e:
                    print(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ {filename}: {e}")
        
        return data
    
    def _load_fits_file(self, file_path: str) -> Dict[str, Any]:
        """
        –ó–∞—Ä–µ–∂–¥–∞ FITS —Ñ–∞–π–ª
        
        Args:
            file_path: –ü—ä—Ç –∫—ä–º —Ñ–∞–π–ª–∞
            
        Returns:
            –î–∞–Ω–Ω–∏ –æ—Ç FITS —Ñ–∞–π–ª–∞
        """
        try:
            with fits.open(file_path) as hdul:
                data = {
                    'header': dict(hdul[0].header),
                    'data': None,
                    'table': None
                }
                
                # –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º–µ –¥–∞–ª–∏ –∏–º–∞ –¥–∞–Ω–Ω–∏
                if len(hdul) > 1:
                    if hdul[1].data is not None:
                        data['table'] = Table(hdul[1].data)
                        data['data'] = hdul[1].data
                
                return data
        except Exception as e:
            print(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ FITS —Ñ–∞–π–ª {file_path}: {e}")
            return {}
    
    def _load_ascii_file(self, file_path: str) -> Dict[str, Any]:
        """
        –ó–∞—Ä–µ–∂–¥–∞ ASCII —Ñ–∞–π–ª
        
        Args:
            file_path: –ü—ä—Ç –∫—ä–º —Ñ–∞–π–ª–∞
            
        Returns:
            –î–∞–Ω–Ω–∏ –æ—Ç ASCII —Ñ–∞–π–ª–∞
        """
        try:
            # –û–ø–∏—Ç–≤–∞–º–µ —Å–µ –¥–∞ –æ–ø—Ä–µ–¥–µ–ª–∏–º —Ñ–æ—Ä–º–∞—Ç–∞
            with open(file_path, 'r') as f:
                first_lines = [f.readline().strip() for _ in range(10)]
            
            # –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º–µ –¥–∞–ª–∏ –∏–º–∞ header
            has_header = any(line.startswith('#') or 
                           not line.replace('.', '').replace('-', '').replace(' ', '').replace('\t', '').isdigit()
                           for line in first_lines[:3] if line)
            
            # –ó–∞—Ä–µ–∂–¥–∞–º–µ –¥–∞–Ω–Ω–∏—Ç–µ
            if has_header:
                data = pd.read_csv(file_path, delim_whitespace=True, comment='#')
            else:
                data = pd.read_csv(file_path, delim_whitespace=True, header=None)
            
            return {
                'dataframe': data,
                'values': data.values,
                'columns': data.columns.tolist()
            }
        except Exception as e:
            print(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ ASCII —Ñ–∞–π–ª {file_path}: {e}")
            return {}
    
    def _load_latex_table(self, file_path: str) -> Dict[str, Any]:
        """
        –ó–∞—Ä–µ–∂–¥–∞ LaTeX —Ç–∞–±–ª–∏—Ü–∞
        
        Args:
            file_path: –ü—ä—Ç –∫—ä–º —Ñ–∞–π–ª–∞
            
        Returns:
            –î–∞–Ω–Ω–∏ –æ—Ç LaTeX —Ç–∞–±–ª–∏—Ü–∞—Ç–∞
        """
        try:
            with open(file_path, 'r') as f:
                content = f.read()
            
            # –û–ø–∏—Ç–≤–∞–º–µ —Å–µ –¥–∞ –∏–∑–≤–ª–µ—á–µ–º –¥–∞–Ω–Ω–∏—Ç–µ –æ—Ç LaTeX —Ñ–æ—Ä–º–∞—Ç–∞
            # –¢–æ–≤–∞ –µ –æ–ø—Ä–æ—Å—Ç–µ–Ω–∞ –≤–µ—Ä—Å–∏—è - –º–æ–∂–µ –¥–∞ —Å–µ –ø–æ–¥–æ–±—Ä–∏
            lines = content.split('\n')
            data_lines = []
            
            for line in lines:
                # –¢—ä—Ä—Å–∏–º —Ä–µ–¥–æ–≤–µ —Å –¥–∞–Ω–Ω–∏ (—Å—ä–¥—ä—Ä–∂–∞—Ç & –∏ \\)
                if '&' in line and '\\' in line:
                    # –ü–æ—á–∏—Å—Ç–≤–∞–º–µ LaTeX –∫–æ–º–∞–Ω–¥–∏—Ç–µ
                    clean_line = re.sub(r'\\[a-zA-Z]+', '', line)
                    clean_line = clean_line.replace('&', ' ').replace('\\', '')
                    clean_line = clean_line.strip()
                    
                    if clean_line:
                        data_lines.append(clean_line)
            
            # –û–ø–∏—Ç–≤–∞–º–µ —Å–µ –¥–∞ –ø–∞—Ä—Å–∏—Ä–∞–º–µ –¥–∞–Ω–Ω–∏—Ç–µ
            parsed_data = []
            for line in data_lines:
                try:
                    values = line.split()
                    numeric_values = []
                    for val in values:
                        try:
                            numeric_values.append(float(val))
                        except ValueError:
                            numeric_values.append(val)
                    parsed_data.append(numeric_values)
                except:
                    continue
            
            return {
                'raw_content': content,
                'parsed_data': parsed_data,
                'n_rows': len(parsed_data)
            }
        except Exception as e:
            print(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ LaTeX —Ñ–∞–π–ª {file_path}: {e}")
            return {}
    
    def extract_redshift_magnitude_data(self) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–∏—á–∞ z –∏ magnitude –¥–∞–Ω–Ω–∏ –æ—Ç –≤—Å–∏—á–∫–∏ –∏–∑—Ç–æ—á–Ω–∏—Ü–∏
        
        Returns:
            –£–Ω–∏—Ñ–∏—Ü–∏—Ä–∞–Ω–∏ –¥–∞–Ω–Ω–∏ –∑–∞ z –∏ magnitude
        """
        unified_data = {
            'pantheon_plus': {},
            'shoes': {},
            'combined': {}
        }
        
        # Pantheon+ –¥–∞–Ω–Ω–∏
        if 'pantheon_plus' in self.loaded_data:
            unified_data['pantheon_plus'] = self._extract_pantheon_z_mag()
        
        # SH0ES –¥–∞–Ω–Ω–∏
        if 'shoes' in self.loaded_data:
            unified_data['shoes'] = self._extract_shoes_z_mag()
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–∞–º–µ –¥–∞–Ω–Ω–∏—Ç–µ
        unified_data['combined'] = self._combine_z_mag_data(unified_data)
        
        return unified_data
    
    def _extract_pantheon_z_mag(self) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–∏—á–∞ z –∏ magnitude –æ—Ç Pantheon+ –¥–∞–Ω–Ω–∏
        
        Returns:
            –†–µ—á–Ω–∏–∫ —Å z –∏ magnitude –¥–∞–Ω–Ω–∏
        """
        data = {}
        
        pantheon_data = self.loaded_data['pantheon_plus']
        
        # –¢—ä—Ä—Å–∏–º –≤ —Ä–∞–∑–ª–∏—á–Ω–∏—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for subdir, files in pantheon_data.items():
            for filename, file_data in files.items():
                if 'dataframe' in file_data:
                    df = file_data['dataframe']
                    
                    # –¢—ä—Ä—Å–∏–º –∫–æ–ª–æ–Ω–∏ –∑–∞ z –∏ magnitude
                    z_cols = [col for col in df.columns if 'z' in col.lower() or 'redshift' in col.lower()]
                    mag_cols = [col for col in df.columns if 'mag' in col.lower() or 'mu' in col.lower()]
                    
                    if z_cols and mag_cols:
                        data[f"{subdir}_{filename}"] = {
                            'z': df[z_cols[0]].values,
                            'magnitude': df[mag_cols[0]].values,
                            'z_column': z_cols[0],
                            'mag_column': mag_cols[0],
                            'n_points': len(df)
                        }
        
        return data
    
    def _extract_shoes_z_mag(self) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–∏—á–∞ z –∏ magnitude –æ—Ç SH0ES –¥–∞–Ω–Ω–∏
        
        Returns:
            –†–µ—á–Ω–∏–∫ —Å z –∏ magnitude –¥–∞–Ω–Ω–∏
        """
        data = {}
        
        shoes_data = self.loaded_data['shoes']
        
        for filename, file_data in shoes_data.items():
            if 'dataframe' in file_data:
                df = file_data['dataframe']
                
                # –¢—ä—Ä—Å–∏–º –∫–æ–ª–æ–Ω–∏ –∑–∞ z –∏ magnitude
                z_cols = [col for col in df.columns if 'z' in str(col).lower() or 'redshift' in str(col).lower()]
                mag_cols = [col for col in df.columns if 'mag' in str(col).lower() or 'mu' in str(col).lower()]
                
                if z_cols and mag_cols:
                    data[filename] = {
                        'z': df[z_cols[0]].values,
                        'magnitude': df[mag_cols[0]].values,
                        'z_column': z_cols[0],
                        'mag_column': mag_cols[0],
                        'n_points': len(df)
                    }
            
            elif 'table' in file_data and file_data['table'] is not None:
                table = file_data['table']
                
                # –¢—ä—Ä—Å–∏–º –∫–æ–ª–æ–Ω–∏ –∑–∞ z –∏ magnitude
                z_cols = [col for col in table.colnames if 'z' in col.lower() or 'redshift' in col.lower()]
                mag_cols = [col for col in table.colnames if 'mag' in col.lower() or 'mu' in col.lower()]
                
                if z_cols and mag_cols:
                    data[filename] = {
                        'z': table[z_cols[0]].data,
                        'magnitude': table[mag_cols[0]].data,
                        'z_column': z_cols[0],
                        'mag_column': mag_cols[0],
                        'n_points': len(table)
                    }
        
        return data
    
    def _combine_z_mag_data(self, unified_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ö–æ–º–±–∏–Ω–∏—Ä–∞ z –∏ magnitude –¥–∞–Ω–Ω–∏ –æ—Ç –≤—Å–∏—á–∫–∏ –∏–∑—Ç–æ—á–Ω–∏—Ü–∏
        
        Args:
            unified_data: –£–Ω–∏—Ñ–∏—Ü–∏—Ä–∞–Ω–∏ –¥–∞–Ω–Ω–∏
            
        Returns:
            –ö–æ–º–±–∏–Ω–∏—Ä–∞–Ω–∏ –¥–∞–Ω–Ω–∏
        """
        all_z = []
        all_mag = []
        sources = []
        
        # Pantheon+ –¥–∞–Ω–Ω–∏
        for key, data in unified_data['pantheon_plus'].items():
            if 'z' in data and 'magnitude' in data:
                all_z.extend(data['z'])
                all_mag.extend(data['magnitude'])
                sources.extend(['pantheon_plus'] * len(data['z']))
        
        # SH0ES –¥–∞–Ω–Ω–∏
        for key, data in unified_data['shoes'].items():
            if 'z' in data and 'magnitude' in data:
                all_z.extend(data['z'])
                all_mag.extend(data['magnitude'])
                sources.extend(['shoes'] * len(data['z']))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–º–µ –≤ numpy –º–∞—Å–∏–≤–∏
        all_z = np.array(all_z)
        all_mag = np.array(all_mag)
        sources = np.array(sources)
        
        # –§–∏–ª—Ç—Ä–∏—Ä–∞–º–µ –≤–∞–ª–∏–¥–Ω–∏ –¥–∞–Ω–Ω–∏
        valid_mask = np.isfinite(all_z) & np.isfinite(all_mag) & (all_z > 0)
        
        return {
            'z': all_z[valid_mask],
            'magnitude': all_mag[valid_mask],
            'sources': sources[valid_mask],
            'n_points': np.sum(valid_mask),
            'z_range': (np.min(all_z[valid_mask]), np.max(all_z[valid_mask])),
            'mag_range': (np.min(all_mag[valid_mask]), np.max(all_mag[valid_mask]))
        }
    
    def get_raw_data_summary(self) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä–∞ —Ä–µ–∑—é–º–µ –Ω–∞ –∑–∞—Ä–µ–¥–µ–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏
        
        Returns:
            –¢–µ–∫—Å—Ç–æ–≤–æ —Ä–µ–∑—é–º–µ
        """
        summary = []
        summary.append("=" * 60)
        summary.append("–†–ï–ó–Æ–ú–ï –ù–ê –°–£–†–û–í–ò –î–ê–ù–ù–ò")
        summary.append("=" * 60)
        summary.append("")
        
        # Pantheon+ –¥–∞–Ω–Ω–∏
        if 'pantheon_plus' in self.loaded_data:
            summary.append("PANTHEON+ –î–ê–ù–ù–ò:")
            summary.append("-" * 20)
            
            for subdir, files in self.loaded_data['pantheon_plus'].items():
                summary.append(f"  {subdir}: {len(files)} —Ñ–∞–π–ª–∞")
                for filename in files.keys():
                    summary.append(f"    - {filename}")
            
            summary.append("")
        
        # SH0ES –¥–∞–Ω–Ω–∏
        if 'shoes' in self.loaded_data:
            summary.append("SH0ES –î–ê–ù–ù–ò:")
            summary.append("-" * 20)
            
            for filename, data in self.loaded_data['shoes'].items():
                file_type = "FITS" if 'table' in data else "ASCII" if 'dataframe' in data else "LaTeX"
                summary.append(f"  {filename} ({file_type})")
                
                if 'dataframe' in data:
                    df = data['dataframe']
                    summary.append(f"    –†–∞–∑–º–µ—Ä: {df.shape[0]} x {df.shape[1]}")
                    summary.append(f"    –ö–æ–ª–æ–Ω–∏: {df.columns.tolist()}")
                elif 'table' in data and data['table'] is not None:
                    table = data['table']
                    summary.append(f"    –†–∞–∑–º–µ—Ä: {len(table)} –∑–∞–ø–∏—Å–∞")
                    summary.append(f"    –ö–æ–ª–æ–Ω–∏: {table.colnames}")
            
            summary.append("")
        
        return "\n".join(summary)
    
    def plot_raw_data_overview(self, save_path: str = None):
        """
        –ì—Ä–∞—Ñ–∏—á–µ–Ω –ø—Ä–µ–≥–ª–µ–¥ –Ω–∞ —Å—É—Ä–æ–≤–∏ –¥–∞–Ω–Ω–∏
        
        Args:
            save_path: –ü—ä—Ç –∑–∞ –∑–∞–ø–∏—Å–≤–∞–Ω–µ
        """
        # –ò–∑–≤–ª–∏—á–∞–º–µ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–∞–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏
        unified_data = self.extract_redshift_magnitude_data()
        
        if not unified_data['combined']:
            print("–ù—è–º–∞ –¥–∞–Ω–Ω–∏ –∑–∞ –ø–æ–∫–∞–∑–≤–∞–Ω–µ")
            return
        
        combined = unified_data['combined']
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. Hubble –¥–∏–∞–≥—Ä–∞–º–∞
        # –°—ä–∑–¥–∞–≤–∞–º–µ —á–∏—Å–ª–æ–≤–∏ –∫–æ–¥–æ–≤–µ –∑–∞ –∏–∑—Ç–æ—á–Ω–∏—Ü–∏—Ç–µ
        unique_sources = np.unique(combined['sources'])
        source_colors = {source: i for i, source in enumerate(unique_sources)}
        color_values = [source_colors[source] for source in combined['sources']]
        
        scatter = axes[0, 0].scatter(combined['z'], combined['magnitude'], 
                                    alpha=0.6, s=20, c=color_values, cmap='viridis')
        axes[0, 0].set_xlabel('–ß–µ—Ä–≤–µ–Ω–æ –æ—Ç–º–µ—Å—Ç–≤–∞–Ω–µ z')
        axes[0, 0].set_ylabel('–ú–æ–¥—É–ª–Ω–∞ –≤–µ–ª–∏—á–∏–Ω–∞')
        axes[0, 0].set_title('Hubble –¥–∏–∞–≥—Ä–∞–º–∞ (—Å—É—Ä–æ–≤–∏ –¥–∞–Ω–Ω–∏)')
        axes[0, 0].grid(True, alpha=0.3)
        
        # –î–æ–±–∞–≤—è–º–µ –ª–µ–≥–µ–Ω–¥–∞
        from matplotlib.colors import ListedColormap
        import matplotlib.cm as cm
        cmap = cm.get_cmap('viridis')
        for i, source in enumerate(unique_sources):
            axes[0, 0].scatter([], [], c=cmap(i/len(unique_sources)), 
                              label=source, s=20)
        axes[0, 0].legend(loc='upper left', fontsize=8)
        
        # 2. –†–∞–∑–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ z
        axes[0, 1].hist(combined['z'], bins=50, alpha=0.7, edgecolor='black')
        axes[0, 1].set_xlabel('–ß–µ—Ä–≤–µ–Ω–æ –æ—Ç–º–µ—Å—Ç–≤–∞–Ω–µ z')
        axes[0, 1].set_ylabel('–ß–µ—Å—Ç–æ—Ç–∞')
        axes[0, 1].set_title('–†–∞–∑–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–µ—Ä–≤–µ–Ω–∏—Ç–µ –æ—Ç–º–µ—Å—Ç–≤–∞–Ω–∏—è')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. –†–∞–∑–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ magnitude
        axes[1, 0].hist(combined['magnitude'], bins=50, alpha=0.7, edgecolor='black')
        axes[1, 0].set_xlabel('–ú–æ–¥—É–ª–Ω–∞ –≤–µ–ª–∏—á–∏–Ω–∞')
        axes[1, 0].set_ylabel('–ß–µ—Å—Ç–æ—Ç–∞')
        axes[1, 0].set_title('–†–∞–∑–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –º–æ–¥—É–ª–Ω–∏—Ç–µ –≤–µ–ª–∏—á–∏–Ω–∏')
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –∏–∑—Ç–æ—á–Ω–∏—Ü–∏
        unique_sources, counts = np.unique(combined['sources'], return_counts=True)
        axes[1, 1].bar(unique_sources, counts)
        axes[1, 1].set_xlabel('–ò–∑—Ç–æ—á–Ω–∏–∫')
        axes[1, 1].set_ylabel('–ë—Ä–æ–π –Ω–∞–±–ª—é–¥–µ–Ω–∏—è')
        axes[1, 1].set_title('–ë—Ä–æ–π –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –ø–æ –∏–∑—Ç–æ—á–Ω–∏–∫')
        axes[1, 1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
        
        # –ü—Ä–∏–Ω—Ç–∏—Ä–∞–º–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        print("\n–°–¢–ê–¢–ò–°–¢–ò–ö–ò –ù–ê –°–£–†–û–í–ò –î–ê–ù–ù–ò:")
        print("-" * 30)
        print(f"–û–±—â–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è: {combined['n_points']}")
        print(f"–î–∏–∞–ø–∞–∑–æ–Ω z: {combined['z_range'][0]:.4f} - {combined['z_range'][1]:.4f}")
        print(f"–î–∏–∞–ø–∞–∑–æ–Ω magnitude: {combined['mag_range'][0]:.2f} - {combined['mag_range'][1]:.2f}")
        
        for source, count in zip(unique_sources, counts):
            print(f"{source}: {count} –Ω–∞–±–ª—é–¥–µ–Ω–∏—è")


def test_raw_data_processor():
    """
    –¢–µ—Å—Ç–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏—è –∑–∞ –ø—Ä–æ—Ü–µ—Å–æ—Ä–∞ –Ω–∞ —Å—É—Ä–æ–≤–∏ –¥–∞–Ω–Ω–∏
    """
    # –°—ä–∑–¥–∞–≤–∞–º–µ –ø—Ä–æ—Ü–µ—Å–æ—Ä
    processor = RawDataProcessor()
    
    # –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º–µ –¥–∞–ª–∏ –¥–∞–Ω–Ω–∏—Ç–µ —Å–∞ –¥–æ—Å—Ç—ä–ø–Ω–∏
    data_path = processor.data_path
    pantheon_path = os.path.join(data_path, "Pantheon+_Data")
    shoes_path = os.path.join(data_path, "SH0ES_Data")
    
    if not os.path.exists(data_path):
        print(f"‚ùå –î–∞–Ω–Ω–∏—Ç–µ –Ω–µ —Å–∞ –¥–æ—Å—Ç—ä–ø–Ω–∏ –≤ {data_path}")
        print("üîß –ò–∑–ø–æ–ª–∑–≤–∞–º–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏ –¥–∞–Ω–Ω–∏ –∑–∞ —Ç–µ—Å—Ç–≤–∞–Ω–µ...")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä–∞–º–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏ –¥–∞–Ω–Ω–∏
        np.random.seed(42)
        n_points = 1000
        
        # –°–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏ redshift –¥–∞–Ω–Ω–∏
        z_synthetic = np.random.exponential(scale=0.5, size=n_points)
        z_synthetic = z_synthetic[z_synthetic < 3.0]  # –û–≥—Ä–∞–Ω–∏—á–∞–≤–∞–º–µ –¥–æ z < 3
        
        # –°–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏ magnitude –¥–∞–Ω–Ω–∏ (—Å–ø–æ—Ä–µ–¥ Standard candles)
        # Œº = 5*log10(d_L) + 25 –≥–¥–µ d_L –µ luminosity distance
        H0 = 70  # km/s/Mpc
        c = 3e5  # km/s
        
        # –û–ø—Ä–æ—Å—Ç–µ–Ω –º–æ–¥–µ–ª –∑–∞ luminosity distance
        d_L = (c / H0) * z_synthetic * (1 + z_synthetic/2)  # –ü—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
        magnitude_synthetic = 5 * np.log10(d_L) + 25
        
        # –î–æ–±–∞–≤—è–º–µ —à—É–º
        magnitude_synthetic += np.random.normal(0, 0.1, len(magnitude_synthetic))
        
        # –°—ä–∑–¥–∞–≤–∞–º–µ —Ñ–∞–ª—à–∏–≤–∏ –¥–∞–Ω–Ω–∏
        processor.loaded_data = {
            'synthetic': {
                'test_data': {
                    'z': z_synthetic,
                    'magnitude': magnitude_synthetic,
                    'sources': ['synthetic'] * len(z_synthetic),
                    'n_points': len(z_synthetic),
                    'z_range': (np.min(z_synthetic), np.max(z_synthetic)),
                    'mag_range': (np.min(magnitude_synthetic), np.max(magnitude_synthetic))
                }
            }
        }
        
        print("‚úÖ –°–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏ –¥–∞–Ω–Ω–∏ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–∏ —É—Å–ø–µ—à–Ω–æ")
        print(f"   –ë—Ä–æ–π —Ç–æ—á–∫–∏: {len(z_synthetic)}")
        print(f"   z –¥–∏–∞–ø–∞–∑–æ–Ω: {np.min(z_synthetic):.3f} - {np.max(z_synthetic):.3f}")
        print(f"   magnitude –¥–∏–∞–ø–∞–∑–æ–Ω: {np.min(magnitude_synthetic):.1f} - {np.max(magnitude_synthetic):.1f}")
        
        return {
            'status': 'success_synthetic',
            'processor': processor,
            'data_summary': '–°–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏ –¥–∞–Ω–Ω–∏ –∏–∑–ø–æ–ª–∑–≤–∞–Ω–∏ –∑–∞ —Ç–µ—Å—Ç–≤–∞–Ω–µ',
            'n_points': len(z_synthetic),
            'z_range': (np.min(z_synthetic), np.max(z_synthetic)),
            'mag_range': (np.min(magnitude_synthetic), np.max(magnitude_synthetic))
        }
    
    else:
        # –ó–∞—Ä–µ–∂–¥–∞–º–µ —Ä–µ–∞–ª–Ω–∏ –¥–∞–Ω–Ω–∏
        print("–ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ Pantheon+ –¥–∞–Ω–Ω–∏...")
        pantheon_data = processor.load_pantheon_plus_data()
        
        print("–ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ SH0ES –¥–∞–Ω–Ω–∏...")
        shoes_data = processor.load_shoes_data()
        
        # –ü–æ–∫–∞–∑–≤–∞–º–µ —Ä–µ–∑—é–º–µ
        print("\n–†–µ–∑—é–º–µ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ:")
        print(processor.get_raw_data_summary())
        
        # –ò–∑–≤–ª–∏—á–∞–º–µ z –∏ magnitude –¥–∞–Ω–Ω–∏
        print("\n–ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ z –∏ magnitude –¥–∞–Ω–Ω–∏...")
        unified_data = processor.extract_redshift_magnitude_data()
        
        # –ü–æ–∫–∞–∑–≤–∞–º–µ –≥—Ä–∞—Ñ–∏–∫–∏
        processor.plot_raw_data_overview()
        
        return {
            'status': 'success_real',
            'processor': processor,
            'data_summary': processor.get_raw_data_summary(),
            'unified_data': unified_data
        }


if __name__ == "__main__":
    processor = test_raw_data_processor() 